{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ScorcaF/mbrl-lib/blob/main/notebooks/pets_example_v0.1.5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnqCJYf8DGw0"
      },
      "source": [
        "#### Note: This example is compatible with versions v0.1.5 or lower, for the most recent version, see [this](https://github.com/facebookresearch/mbrl-lib/blob/main/notebooks/pets_example.ipynb) notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "pip install mbrl\n",
        "pip install omegaconf\n",
        "apt-get install swig\n",
        "pip install -U matplotlib\n",
        "# install required system dependencies\n",
        "apt-get install -y xvfb x11-utils\n",
        "\n",
        "# install required python dependencies (might need to install additional gym extras depending)\n",
        "pip install gym[box2d]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*\n",
        "\n",
        "pip3 install box2d-py\n",
        "pip3 install gym[Box_2D]\n",
        "pip install stable_baselines3\n",
        "\n"
      ],
      "metadata": {
        "id": "rJDIkTSCDeuQ",
        "outputId": "103c180c-174f-4e4f-90fd-9fe3aa18683f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mbrl\n",
            "  Downloading mbrl-0.1.5-py3-none-any.whl (134 kB)\n",
            "Collecting hydra-core==1.0.3\n",
            "  Downloading hydra_core-1.0.3-py3-none-any.whl (122 kB)\n",
            "Collecting gym==0.17.2\n",
            "  Downloading gym-0.17.2.tar.gz (1.6 MB)\n",
            "Collecting imageio>=2.9.0\n",
            "  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
            "Collecting matplotlib>=3.3.1\n",
            "  Downloading matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mbrl) (1.1.0)\n",
            "Requirement already satisfied: jupyter>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mbrl) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.7/dist-packages (from mbrl) (1.21.6)\n",
            "Collecting pytest>=6.0.1\n",
            "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
            "Requirement already satisfied: tensorboard>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from mbrl) (2.8.0)\n",
            "Collecting sk-video>=1.1.10\n",
            "  Downloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2->mbrl) (1.7.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2->mbrl) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.17.2->mbrl) (1.3.0)\n",
            "Collecting omegaconf>=2.0.2\n",
            "  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core==1.0.3->mbrl) (5.8.0)\n",
            "Collecting pillow>=8.3.2\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->mbrl) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->mbrl) (5.6.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->mbrl) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->mbrl) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->mbrl) (7.7.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0.0->mbrl) (5.2.0)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.1->mbrl) (21.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.1->mbrl) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.1->mbrl) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.1->mbrl) (1.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.1->mbrl) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.3.1->mbrl) (4.1.1)\n",
            "Collecting PyYAML>=5.1.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Collecting omegaconf>=2.0.2\n",
            "  Downloading omegaconf-2.2.1-py3-none-any.whl (78 kB)\n",
            "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.2->mbrl) (0.16.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest>=6.0.1->mbrl) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.0.1->mbrl) (2.0.1)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.0.1->mbrl) (1.11.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.0.1->mbrl) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.0.1->mbrl) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=6.0.1->mbrl) (3.8.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.1->mbrl) (1.15.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (1.47.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->mbrl) (3.17.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.0->mbrl) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.0->mbrl) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.0->mbrl) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.0->mbrl) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.0->mbrl) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.0->mbrl) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.0->mbrl) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.0->mbrl) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.0->mbrl) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.0->mbrl) (3.2.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1.0.0->mbrl) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1.0.0->mbrl) (5.3.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1.0.0->mbrl) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1.0.0->mbrl) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter>=1.0.0->mbrl) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter>=1.0.0->mbrl) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter>=1.0.0->mbrl) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter>=1.0.0->mbrl) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter>=1.0.0->mbrl) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter>=1.0.0->mbrl) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter>=1.0.0->mbrl) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter>=1.0.0->mbrl) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter>=1.0.0->mbrl) (1.1.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter>=1.0.0->mbrl) (3.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->mbrl) (1.8.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->mbrl) (4.11.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->mbrl) (0.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->mbrl) (2.11.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0.0->mbrl) (5.4.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter>=1.0.0->mbrl) (23.2.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0.0->mbrl) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter>=1.0.0->mbrl) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->mbrl) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->mbrl) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->mbrl) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->mbrl) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->mbrl) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0.0->mbrl) (5.0.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter>=1.0.0->mbrl) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter>=1.0.0->mbrl) (2.15.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter>=1.0.0->mbrl) (0.18.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->mbrl) (0.5.1)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter>=1.0.0->mbrl) (2.1.0)\n",
            "Building wheels for collected packages: gym, antlr4-python3-runtime\n",
            "  Building wheel for gym (setup.py): started\n",
            "  Building wheel for gym (setup.py): finished with status 'done'\n",
            "  Created wheel for gym: filename=gym-0.17.2-py3-none-any.whl size=1650890 sha256=b1794f48bbce619f6daf43eb5a92ce4697c084a5b45e75d6e25057343f7d318f\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/e1/58/89a2aa24e6c2cc800204fc02010612afdf200926c4d6bfe315\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=4b66bcb1a0402df4b14cd7a31967cb0228bfe997eb754df2f8690dd42ab88d5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built gym antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, antlr4-python3-runtime, pluggy, pillow, omegaconf, fonttools, sk-video, pytest, matplotlib, imageio, hydra-core, gym, mbrl\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 fonttools-4.34.4 gym-0.17.2 hydra-core-1.0.3 imageio-2.19.3 matplotlib-3.5.2 mbrl-0.1.5 omegaconf-2.1.2 pillow-9.2.0 pluggy-1.0.0 pytest-7.1.2 sk-video-1.1.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.7/dist-packages (2.1.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from omegaconf) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf) (6.0)\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,100 kB of archives.\n",
            "After this operation, 5,822 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 1,100 kB in 2s (637 kB/s)\n",
            "Selecting previously unselected package swig3.0.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 155653 files and directories currently installed.)\r\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\r\n",
            "Unpacking swig3.0 (3.0.12-1) ...\r\n",
            "Selecting previously unselected package swig.\r\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\r\n",
            "Unpacking swig (3.0.12-1) ...\r\n",
            "Setting up swig3.0 (3.0.12-1) ...\r\n",
            "Setting up swig (3.0.12-1) ...\r\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libxxf86dga1\n",
            "Suggested packages:\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  libxxf86dga1 x11-utils xvfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 994 kB of archives.\n",
            "After this operation, 2,982 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.11 [785 kB]\n",
            "Fetched 994 kB in 2s (488 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 156444 files and directories currently installed.)\r\n",
            "Preparing to unpack .../libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\r\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\r\n",
            "Selecting previously unselected package x11-utils.\r\n",
            "Preparing to unpack .../x11-utils_7.7+3build1_amd64.deb ...\r\n",
            "Unpacking x11-utils (7.7+3build1) ...\r\n",
            "Selecting previously unselected package xvfb.\r\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.11_amd64.deb ...\r\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.11) ...\r\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.11) ...\r\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\r\n",
            "Setting up x11-utils (7.7+3build1) ...\r\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\r\n",
            "\r\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[box2d]==0.17.* in /usr/local/lib/python3.7/dist-packages (0.17.2)\n",
            "Collecting pyvirtualdisplay==0.2.*\n",
            "  Downloading PyVirtualDisplay-0.2.5-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: PyOpenGL==3.1.* in /usr/local/lib/python3.7/dist-packages (3.1.6)\n",
            "Collecting PyOpenGL-accelerate==3.1.*\n",
            "  Downloading PyOpenGL-accelerate-3.1.5.tar.gz (538 kB)\n",
            "Collecting EasyProcess\n",
            "  Downloading EasyProcess-1.1-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.7.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.21.6)\n",
            "Collecting box2d-py~=2.3.5\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]==0.17.*) (0.16.0)\n",
            "Building wheels for collected packages: PyOpenGL-accelerate\n",
            "  Building wheel for PyOpenGL-accelerate (setup.py): started\n",
            "  Building wheel for PyOpenGL-accelerate (setup.py): finished with status 'done'\n",
            "  Created wheel for PyOpenGL-accelerate: filename=PyOpenGL_accelerate-3.1.5-cp37-cp37m-linux_x86_64.whl size=1599484 sha256=d9b245c28e977b1aa4c16238c73fb0aa23b682af1f162d4e71d92c47cbe58624\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/f5/6f/169afb3f2d476c5e807f8515b3c9bc9b819c3962316aa804eb\n",
            "Successfully built PyOpenGL-accelerate\n",
            "Installing collected packages: EasyProcess, box2d-py, pyvirtualdisplay, PyOpenGL-accelerate\n",
            "Successfully installed EasyProcess-1.1 PyOpenGL-accelerate-3.1.5 box2d-py-2.3.8 pyvirtualdisplay-0.2.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (2.3.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.2)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.7.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-1.6.0-py3-none-any.whl (177 kB)\n",
            "Collecting gym==0.21\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (3.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable_baselines3) (1.3.5)\n",
            "Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable_baselines3) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable_baselines3) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym==0.21->stable_baselines3) (3.8.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (9.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (4.34.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (1.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines3) (21.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable_baselines3) (2022.1)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py): started\n",
            "  Building wheel for gym (setup.py): finished with status 'done'\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616825 sha256=fe1ee6d0179e266325a815c5ef8db8fa55922aa3d63b2e70e2c09643681ce641\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
            "Successfully built gym\n",
            "Installing collected packages: gym, stable-baselines3\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.2\n",
            "    Uninstalling gym-0.17.2:\n",
            "      Successfully uninstalled gym-0.17.2\n",
            "Successfully installed gym-0.21.0 stable-baselines3-1.6.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\n",
            "WARNING: gym 0.17.2 does not provide the extra 'box_2d'\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mbrl 0.1.5 requires gym==0.17.2, but you have gym 0.21.0 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyvirtualdisplay\n",
        "\n",
        "_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
        "                                    size=(1400, 900))\n",
        "_ = _display.start()\n",
        "\n",
        "_display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
        "_ = _display.start()"
      ],
      "metadata": {
        "id": "p5CP1RVP01tl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from collections import deque\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class CenterDistanceObsWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(1,), dtype=env.observation_space.dtype)\n",
        "\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return self.process_obs(observation)\n",
        "\n",
        "\n",
        "    def process_obs(self, obs):\n",
        "        # Apply following functions\n",
        "        obs = self.green_mask(obs)\n",
        "        obs = self.gray_scale(obs)\n",
        "        obs = self.blur_image(obs)\n",
        "        obs = self.crop(obs)\n",
        "        obs = self.get_distance_from_center(obs)\n",
        "        return obs\n",
        "\n",
        "    def green_mask(self, observation):\n",
        "        hsv = cv2.cvtColor(observation, cv2.COLOR_BGR2HSV)\n",
        "        mask_green = cv2.inRange(hsv, (36, 25, 25), (70, 255, 255))\n",
        "\n",
        "        ## slice the green\n",
        "        imask_green = mask_green > 0\n",
        "        green = np.zeros_like(observation, np.uint8)\n",
        "        green[imask_green] = observation[imask_green]\n",
        "        return (green)\n",
        "\n",
        "    def gray_scale(self, observation):\n",
        "        gray = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
        "        return gray\n",
        "\n",
        "    def blur_image(self, observation):\n",
        "        blur = cv2.GaussianBlur(observation, (5, 5), 0)\n",
        "        return blur\n",
        "\n",
        "    def canny_edge_detector(self, observation):\n",
        "        canny = cv2.Canny(observation, 50, 150)\n",
        "        return canny\n",
        "\n",
        "    def crop(self, observation):\n",
        "        # cut stats\n",
        "        return observation[65:67, 24:73]\n",
        "\n",
        "    def get_distance_from_center(self, observation):\n",
        "    # find all non zero values in the cropped strip.\n",
        "        # These non zero points(white pixels) corresponds to the edges of the road\n",
        "        nz = cv2.findNonZero(observation)\n",
        "        image_center = 24\n",
        "        if nz is None:\n",
        "            observation = 1.0\n",
        "\n",
        "        center_coord = (nz[:, 0, 0].max() + nz[:, 0, 0].min())/2\n",
        "        #normalize\n",
        "        observation = np.abs((center_coord - image_center))/24\n",
        "        return observation\n",
        "\n",
        "#Lines for sanity check\n",
        "# env = gym.make(\"CarRacing-v0\")\n",
        "# env = CenterDistanceObsWrapper(env)\n",
        "# env.reset()"
      ],
      "metadata": {
        "id": "w6idSm5DZGhD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4llhe_dmDGw4"
      },
      "source": [
        "# Preview\n",
        "\n",
        "In this example, we are going to use our toolbox to write the [PETS](https://arxiv.org/pdf/1805.12114.pdf) algorithm (Chua at al., 2018), and use it to solve a continuous version of the cartpole environment. PETS is a model-based algorithm that consists of two main components: an ensemble of probabilistic models (each a feed-forward neural network), and a planner using the [Cross-Entropy Method](https://people.smp.uq.edu.au/DirkKroese/ps/aortut.pdf) (de Boer et al., 2004). \n",
        "\n",
        "A basic implementation of this algorithm consists of the following sequence of steps:\n",
        "\n",
        "1. Gather data using an exploration policy\n",
        "2. Repeat:<br>\n",
        "  2.1. Train the dynamics model using all available data.<br>\n",
        "  2.2. Do a trajectory on the environment, choosing actions with the planner, using the dynamics model to simulate environment transitions.\n",
        "  \n",
        "The ensemble model is trained to predict the environment's dynamics, and the planner tries to find high-reward trajectories over the model dynamics. \n",
        "\n",
        "To implement this using `MBRL-Lib`, we will use an ensemble of neural networks (NNs) modelling Gaussian distributions (available in the [mbrl.models](https://luisenp.github.io/mbrl-lib/models.html#mbrl.models.GaussianMLP) module), and a trajectory optimizer agent that uses CEM (available in the [mbrl.planning](https://luisenp.github.io/mbrl-lib/planning.html#mbrl.planning.TrajectoryOptimizerAgent) module). We will also rely on several of the utilities available in the [mbrl.util](https://luisenp.github.io/mbrl-lib/util.html) module. Finally, we will wrap the dynamics model into a [gym-like environment](https://luisenp.github.io/mbrl-lib/models.html#mbrl.models.ModelEnv) over which we can plan action sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KcLkHRkfDGw5"
      },
      "outputs": [],
      "source": [
        "\n",
        "from IPython import display\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import omegaconf\n",
        "import gym \n",
        "\n",
        "import mbrl.env.cartpole_continuous as cartpole_env\n",
        "import mbrl.env.reward_fns as reward_fns\n",
        "import mbrl.env.termination_fns as termination_fns\n",
        "import mbrl.models as models\n",
        "import mbrl.planning as planning\n",
        "import mbrl.util.common as common_util\n",
        "import mbrl.util as util\n",
        "\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "mpl.rcParams.update({\"font.size\": 16})\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltbhs2puDGw6"
      },
      "source": [
        "# Creating the environment\n",
        "\n",
        "First we instantiate the environment and specify which reward function and termination function to use with the gym-like environment wrapper, along with some utility objects. The termination function tells the wrapper if an observation should cause an episode to end or not, and it is an input used in some algorithms, like [MBPO](https://github.com/JannerM/mbpo/blob/master/mbpo/static/halfcheetah.py). The reward function is used to compute the value of the reward given an observation, and it's used by some algorithms, like [PETS](https://github.com/kchua/handful-of-trials/blob/77fd8802cc30b7683f0227c90527b5414c0df34c/dmbrl/controllers/MPC.py#L65)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g6WlUmpQDGw7"
      },
      "outputs": [],
      "source": [
        "seed = 0\n",
        "env = gym.make(\"CarRacing-v0\")\n",
        "env = CenterDistanceObsWrapper(env)\n",
        "env.seed(seed)\n",
        "rng = np.random.default_rng(seed=0)\n",
        "generator = torch.Generator(device=device)\n",
        "generator.manual_seed(seed)\n",
        "obs_shape = env.observation_space.shape\n",
        "act_shape = env.action_space.shape\n",
        "\n",
        "# This functions allows the model to evaluate the true rewards given an observation \n",
        "reward_fn = reward_fns.car1D\n",
        "# This function allows the model to know if an observation should make the episode end\n",
        "term_fn = termination_fns.car1D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNCnXxZ0DGw7"
      },
      "source": [
        "# Hydra configuration\n",
        "\n",
        "MBRL-Lib uses [Hydra](https://github.com/facebookresearch/hydra) to manage configurations. For the purpose of this example, you can think of the configuration object as a dictionary with key/value pairs--and equivalent attributes--that specify the model and algorithmic options. Our toolbox expects the configuration object to be organized as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "g_HqjFroDGw8"
      },
      "outputs": [],
      "source": [
        "trial_length = 200\n",
        "num_trials = 10\n",
        "ensemble_size = 5\n",
        "\n",
        "# Everything with \"???\" indicates an option with a missing value.\n",
        "# Our utility functions will fill in these details using the \n",
        "# environment information\n",
        "cfg_dict = {\n",
        "    # dynamics model configuration\n",
        "    \"dynamics_model\": {\n",
        "        \"model\": \n",
        "        {\n",
        "            \"_target_\": \"mbrl.models.GaussianMLP\",\n",
        "            \"device\": device,\n",
        "            \"num_layers\": 3,\n",
        "            \"ensemble_size\": ensemble_size,\n",
        "            \"hid_size\": 200,\n",
        "            \"in_size\": \"???\",\n",
        "            \"out_size\": \"???\",\n",
        "            \"deterministic\": False,\n",
        "            \"propagation_method\": \"fixed_model\",\n",
        "            # can also configure activation function for GaussianMLP\n",
        "            \"activation_fn_cfg\": {\n",
        "                \"_target_\": \"torch.nn.LeakyReLU\",\n",
        "                \"negative_slope\": 0.01\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    # options for training the dynamics model\n",
        "    \"algorithm\": {\n",
        "        \"learned_rewards\": False,\n",
        "        \"target_is_delta\": True,\n",
        "        \"normalize\": True,\n",
        "    },\n",
        "    # these are experiment specific options\n",
        "    \"overrides\": {\n",
        "        \"trial_length\": trial_length,\n",
        "        \"num_steps\": num_trials * trial_length,\n",
        "        \"model_batch_size\": 32,\n",
        "        \"validation_ratio\": 0.05\n",
        "    }\n",
        "}\n",
        "cfg = omegaconf.OmegaConf.create(cfg_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlf__BJwDGw8"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\"><b>Note: </b> This example uses a probabilistic ensemble. You can also use a fully deterministic model with class GaussianMLP by setting ensemble_size=1, and deterministic=True. </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqRE0d_cDGw8"
      },
      "source": [
        "# Creating a dynamics model\n",
        "\n",
        "Given the configuration above, the following two lines of code create a wrapper for 1-D transition reward models, and a gym-like environment that wraps it, which we can use for simulating the real environment. The 1-D model wrapper takes care of creating input/output data tensors to the underlying NN model (by concatenating observations, actions and rewards appropriately), normalizing the input data to the model, and other data processing tasks (e.g., converting observation targets to deltas with respect to the input observation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1-fEOt1DGw9",
        "outputId": "3a29a663-f8b6-4855-ca5b-b5a98f369593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/hydra/utils.py:32: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
            "  if OmegaConf.is_none(config):\n"
          ]
        }
      ],
      "source": [
        "# Create a 1-D dynamics model for this environment\n",
        "dynamics_model = common_util.create_one_dim_tr_model(cfg, obs_shape, act_shape)\n",
        "\n",
        "# Create a gym-like environment to encapsulate the model\n",
        "model_env = models.ModelEnv(env, dynamics_model, term_fn, reward_fn, generator=generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kw3vS5XDGw-"
      },
      "source": [
        "# Create a replay buffer\n",
        "\n",
        "We can create a replay buffer for this environment an configuration using the following method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ctfk3CXBDGw-"
      },
      "outputs": [],
      "source": [
        "replay_buffer = common_util.create_replay_buffer(cfg, obs_shape, act_shape, rng=rng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpPm5mkIDGw-"
      },
      "source": [
        "We can now populate the replay buffer with random trajectories of a desired length, using a single function call to `util.rollout_agent_trajectories`. Note that we pass an agent of type `planning.RandomAgent` to generate the actions; however, this method accepts any agent that is a subclass of `planning.Agent`, allowing changing exploration strategies with minimal changes to the code. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iVW6k4qDGw-",
        "outputId": "e938aa44-ad0c-4eff-b625-dee958d376ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Track generation: 1143..1442 -> 299-tiles track\n",
            "# samples stored 200\n"
          ]
        }
      ],
      "source": [
        "common_util.rollout_agent_trajectories(\n",
        "    env,\n",
        "    trial_length, # initial exploration steps\n",
        "    planning.RandomAgent(env),\n",
        "    {}, # keyword arguments to pass to agent.act()\n",
        "    replay_buffer=replay_buffer,\n",
        "    trial_length=trial_length)\n",
        "\n",
        "print(\"# samples stored\", replay_buffer.num_stored)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAejQfu1DGw_"
      },
      "source": [
        "# CEM Agent\n",
        "\n",
        "The following config object and the subsequent function call create an agent that can plan using the Cross-Entropy Method over the model environment created above. When calling `planning.create_trajectory_optim_agent_for_model`, we also specify how many particles to use when propagating model uncertainty, as well as the uncertainty propagation method, \"fixed_model\", which corresponds to the method TS$\\infty$ in the PETS paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdCpzWE_DGw_",
        "outputId": "faa331df-2eee-42c4-d71e-f3d1a32197a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/hydra/utils.py:32: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
            "  if OmegaConf.is_none(config):\n"
          ]
        }
      ],
      "source": [
        "agent_cfg = omegaconf.OmegaConf.create({\n",
        "    # this class evaluates many trajectories and picks the best one\n",
        "    \"_target_\": \"mbrl.planning.TrajectoryOptimizerAgent\",\n",
        "    \"planning_horizon\": 15,\n",
        "    \"replan_freq\": 1,\n",
        "    \"verbose\": False,\n",
        "    \"action_lb\": \"???\",\n",
        "    \"action_ub\": \"???\",\n",
        "    # this is the optimizer to generate and choose a trajectory\n",
        "    \"optimizer_cfg\": {\n",
        "        \"_target_\": \"mbrl.planning.CEMOptimizer\",\n",
        "        \"num_iterations\": 5,\n",
        "        \"elite_ratio\": 0.1,\n",
        "        \"population_size\": 500,\n",
        "        \"alpha\": 0.1,\n",
        "        \"device\": device,\n",
        "        \"lower_bound\": \"???\",\n",
        "        \"upper_bound\": \"???\",\n",
        "        \"return_mean_elites\": True,\n",
        "    }\n",
        "})\n",
        "\n",
        "agent = planning.create_trajectory_optim_agent_for_model(\n",
        "    model_env,\n",
        "    agent_cfg,\n",
        "    num_particles=20\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHI9marqDGw_"
      },
      "source": [
        "# Running PETS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN12-vKkDGw_"
      },
      "source": [
        "Having a model and an agent, we can now run PETS with a simple loop and a few function calls. The first code block creates a callback to pass to the model trainer to accumulate the training losses and validation scores observed. The second block is just a utility function to update the agent's visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "InCraGnpDGw_"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "val_scores = []\n",
        "\n",
        "def train_callback(_model, _total_calls, _epoch, tr_loss, val_score, _best_val):\n",
        "    train_losses.append(tr_loss)\n",
        "    val_scores.append(val_score.mean().item())   # this returns val score per ensemble model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Hhkmkv3NDGxA"
      },
      "outputs": [],
      "source": [
        "def update_axes(_axs, _frame, _text, _trial, _steps_trial, _all_rewards, force_update=False):\n",
        "    if not force_update and (_steps_trial % 10 != 0):\n",
        "        return\n",
        "    _axs[0].imshow(_frame)\n",
        "    _axs[0].set_xticks([])\n",
        "    _axs[0].set_yticks([])\n",
        "    _axs[1].clear()\n",
        "    _axs[1].set_xlim([0, num_trials + .1])\n",
        "    _axs[1].set_ylim([0, 200])\n",
        "    _axs[1].set_xlabel(\"Trial\")\n",
        "    _axs[1].set_ylabel(\"Trial reward\")\n",
        "    _axs[1].plot(_all_rewards, 'bs-')\n",
        "    _text.set_text(f\"Trial {_trial + 1}: {_steps_trial} steps\")\n",
        "    display.display(plt.gcf())  \n",
        "    display.clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUGYKx_JDGxA"
      },
      "source": [
        "The following lines implement the PETS algorithm. First, we create a model trainer and pass some hyperparameters for the optimizer (Adam), along with references to the model instance to use. Then we start a loop where we execute actions of ``agent`` in the environment and train the model at the beginning of the episode (by calling ``model_trainer.train()``. At every step in the loop, we execute an agent action in the environment and populate the replay buffer by calling ``util.step_env_and_add_to_buffer()``. Importantly, at the beginning of each episode we also call ``agent.reset()`` to clear any episode dependent cache; in the case of a ``TrajectoryOptimizerAgent``, this means clearing the previous action sequence found, which is shifted at every call to obtain an initial solution for the optimizer. \n",
        "\n",
        "The rest of the code is mostly bookkeeping to keep track of the total reward observed during each episode, and to make sure episodes terminate after some desired length. After running this code, you should see the agent reaching the maximum reward of 200 after a few episodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": true,
        "id": "93Mqd2PVDGxA",
        "outputId": "24b78e4a-93e7-442a-e7b7-9e55faefb063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Track generation: 964..1212 -> 248-tiles track\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "Track generation: 1176..1474 -> 298-tiles track\n",
            "Track generation: 1283..1608 -> 325-tiles track\n",
            "Track generation: 1217..1526 -> 309-tiles track\n",
            "Track generation: 1096..1374 -> 278-tiles track\n",
            "Track generation: 1198..1501 -> 303-tiles track\n",
            "Track generation: 1159..1453 -> 294-tiles track\n",
            "Track generation: 957..1205 -> 248-tiles track\n",
            "Track generation: 1181..1480 -> 299-tiles track\n",
            "Track generation: 979..1234 -> 255-tiles track\n",
            "Track generation: 1320..1654 -> 334-tiles track\n"
          ]
        }
      ],
      "source": [
        "# Create a trainer for the model\n",
        "model_trainer = models.ModelTrainer(dynamics_model, optim_lr=1e-3, weight_decay=5e-5)\n",
        "num_trials = 10\n",
        "# Create visualization objects\n",
        "# fig, axs = plt.subplots(1, 2, figsize=(14, 3.75), gridspec_kw={\"width_ratios\": [1, 1]})\n",
        "# ax_text = axs[0].text(300, 50, \"\")\n",
        "    \n",
        "# Main PETS loop\n",
        "all_rewards = [0]\n",
        "for trial in range(num_trials):\n",
        "    obs = env.reset()    \n",
        "    agent.reset()\n",
        "    \n",
        "    done = False\n",
        "    total_reward = 0.0\n",
        "    steps_trial = 0\n",
        "    # update_axes(axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, all_rewards)\n",
        "    while not done:\n",
        "        # --------------- Model Training -----------------\n",
        "        if steps_trial == 0:\n",
        "            dynamics_model.update_normalizer(replay_buffer.get_all())  # update normalizer stats --> all the input arrays must have same number of dimensions, but the array at index 0 has 4 dimension(s) and the array at index 1 has 2 dimension(s)\n",
        "            \n",
        "            dataset_train, dataset_val = common_util.get_basic_buffer_iterators(\n",
        "                replay_buffer,\n",
        "                batch_size=cfg.overrides.model_batch_size,\n",
        "                val_ratio=cfg.overrides.validation_ratio,\n",
        "                ensemble_size=ensemble_size,\n",
        "                shuffle_each_epoch=True,\n",
        "                bootstrap_permutes=False,  # build bootstrap dataset using sampling with replacement\n",
        "            )\n",
        "                \n",
        "            model_trainer.train(\n",
        "                dataset_train, \n",
        "                dataset_val=dataset_val, \n",
        "                num_epochs=50, \n",
        "                patience=10, \n",
        "                callback=train_callback,\n",
        "            )\n",
        "\n",
        "        # --- Doing env step using the agent and adding to model dataset ---\n",
        "        next_obs, reward, done, _ = common_util.step_env_and_add_to_buffer(\n",
        "            env, obs, agent, {}, replay_buffer)\n",
        "            \n",
        "        # update_axes(\n",
        "            # axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, all_rewards)\n",
        "        \n",
        "        obs = next_obs\n",
        "        total_reward += reward\n",
        "        steps_trial += 1\n",
        "        \n",
        "        if steps_trial == trial_length:\n",
        "            break\n",
        "    \n",
        "    all_rewards.append(total_reward)\n",
        "\n",
        "# update_axes(axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, all_rewards, force_update=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajaq-vjzDGxB"
      },
      "source": [
        "Finally, below we check the results of the trainer callback, which show the training loss and validation score across all calls to ``model_trainer.train()``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu4s7FznDGxB"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
        "ax[0].plot(train_losses)\n",
        "ax[0].set_xlabel(\"Total training epochs\")\n",
        "ax[0].set_ylabel(\"Training loss (avg. NLL)\")\n",
        "ax[1].plot(val_scores)\n",
        "ax[1].set_xlabel(\"Total training epochs\")\n",
        "ax[1].set_ylabel(\"Validation score (avg. MSE)\")\n",
        "plt.show()\n",
        "\n",
        "train_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2hZ_d1GDGxB"
      },
      "source": [
        "# Where to learn more about MBRL?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVRhVhAMDGxB"
      },
      "source": [
        "To learn about the other features of the library, please check out our [documentation](https://facebookresearch.github.io/mbrl-lib/). Also take a look at our provided implementations of [PETS](https://github.com/facebookresearch/mbrl-lib/blob/main/mbrl/algorithms/pets.py), [MBPO](https://github.com/facebookresearch/mbrl-lib/blob/main/mbrl/algorithms/mbpo.py), and [PlaNet](https://github.com/facebookresearch/mbrl-lib/blob/main/mbrl/algorithms/planet.py), and their configuration [files](https://github.com/facebookresearch/mbrl-lib/tree/main/mbrl/examples/conf)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "MBRL v0.1.5",
      "language": "python",
      "name": "mbrl_015"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "name": "pets_example_v0.1.5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}